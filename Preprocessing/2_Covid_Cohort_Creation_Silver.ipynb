{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ty_YA-cLBpyr"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_colwidth', 250)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cohort Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cohort Conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_directory = '/mnt/datasets/fastcovnet/'\n",
    "\n",
    "resolution = '224'\n",
    "columnToPredict = 'Case_type'  # Just to remove cases where columnToPredict is NULL\n",
    "\n",
    "min_days_case_since_positive = -2\n",
    "max_days_case_since_positive = 14\n",
    "\n",
    "max_days_control_since_positive = -60\n",
    "\n",
    "patientOnlyInOneCase = 0\n",
    "keepOneImage_PatientViewPosition = 0\n",
    "keepOnlyBurnedInAnnotationNO = 0\n",
    "keepOnlyConsistentData = 1\n",
    "filterDaysSincePositive = 1\n",
    "filterByModalities = 0\n",
    "filterByBodyPartExamined = 1\n",
    "filterByViewPosition = 1\n",
    "filterByManufacturer = 1\n",
    "filterByManufacturerModelName = 1\n",
    "filterByDeviceSerialNumber = 0\n",
    "\n",
    "BurnedInAnnotation = [\"NO\"]    # To be safe, we start by only selecting BurnedInAnnotation = NO. Looks like all of the main ones have NO.\n",
    "\n",
    "Modalities = [\"DX\"]\n",
    "\n",
    "BodyPartExamined = [\"CHEST\", \"TORAX\", \"THORAX\", \"TÃ³RAX\"]\n",
    "\n",
    "ViewPosition = [\n",
    "\"PA\"\n",
    "# ,\"LL\"\n",
    "# ,\"AP\"\n",
    "]\n",
    "\n",
    "Manufacturer = [\n",
    "\"Philips Medical Systems\"\n",
    "]\n",
    "\n",
    "ManufacturerModelName = [\n",
    "\"DigitalDiagnost\"\n",
    "]\n",
    "\n",
    "DeviceSerialNumber = [\n",
    "\"****\", # (...)\n",
    "]\n",
    "\n",
    "random_seed = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset = pd.read_csv(os.path.join(working_directory,'full_covid_dataset.csv'),\"|\")\n",
    "# full_dataset = pd.read_csv(os.path.join(working_directory,'full_covid_dataset_inferenceVP.csv'),\"|\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of initial images: 293849\n",
      "Number of images after removing RX done in days where we can't be sure whether it's Case or Control: 243758\n",
      "Number of images after removing cases where DICOM Date doesn't match SIMDCAT BBDD Date: 242128\n",
      "Number of images after filtering by Body Part: 207427\n",
      "Number of images after filtering by View Position: 62119\n",
      "Number of images after filtering by Manufacturer: 39629\n",
      "Number of images after filtering by Manufacturer Model Name: 38063\n",
      "Number of images after removing cases where predicted variable is NULL: 38063\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of initial images: \" + str(full_dataset.shape[0]))\n",
    "\n",
    "data = full_dataset\n",
    "\n",
    "# Remove images where we can't be sure in which category they'll go because they're a bit earlier than the PCR\n",
    "if filterDaysSincePositive:\n",
    "    data = data[(data.Dies_desde_positiu<=max_days_control_since_positive) | (data.Dies_desde_positiu.isna()) | ((data.Dies_desde_positiu>=min_days_case_since_positive) & (data.Dies_desde_positiu<=max_days_case_since_positive))]\n",
    "    print(\"Number of images after removing RX done in days where we can't be sure whether it's Case or Control: \" + str(data.shape[0]))\n",
    "\n",
    "# Remove images where DICOM Date doesn't match SIMDCAT BBDD Date\n",
    "if keepOnlyConsistentData:\n",
    "    data = data[data.StudyDate==(data[\"StudyDateTime\"].str[:4] + data[\"StudyDateTime\"].str[5:7] + data[\"StudyDateTime\"].str[8:10]).astype(int)]\n",
    "    print(\"Number of images after removing cases where DICOM Date doesn't match SIMDCAT BBDD Date: \" + str(data.shape[0]))\n",
    "\n",
    "# Select only images with BurnedInAnnotation = NO\n",
    "if keepOnlyBurnedInAnnotationNO:\n",
    "    data = data[data.BurnedInAnnotation.isin(BurnedInAnnotation)]\n",
    "    print(\"Number of images after keeping only BurnedInAnnotation = NO: \" + str(data.shape[0]))\n",
    "\n",
    "# Select only specific Body Parts\n",
    "if filterByBodyPartExamined:\n",
    "    data = data[data.BodyPartExamined.isin(BodyPartExamined)]\n",
    "    print(\"Number of images after filtering by Body Part: \" + str(data.shape[0]))\n",
    "\n",
    "# Select only specific ViewPositions\n",
    "if filterByViewPosition:\n",
    "    data = data[data.ViewPosition.isin(ViewPosition)]\n",
    "    print(\"Number of images after filtering by View Position: \" + str(data.shape[0]))\n",
    "    \n",
    "# Select only specific Modalities\n",
    "if filterByModalities:\n",
    "    data = data[data.Modality.isin(Modalities)]\n",
    "    print(\"Number of images after filtering by Modality: \" + str(data.shape[0]))\n",
    "\n",
    "# Select only specific Manufacturer\n",
    "if filterByManufacturer:\n",
    "    data = data[data.Manufacturer.isin(Manufacturer)]\n",
    "    print(\"Number of images after filtering by Manufacturer: \" + str(data.shape[0]))\n",
    "\n",
    "# Select only specific ManufacturerModelName (should be superseded by the SerialNumber)\n",
    "if filterByManufacturerModelName:\n",
    "    data = data[data.ManufacturerModelName.isin(ManufacturerModelName)]\n",
    "    print(\"Number of images after filtering by Manufacturer Model Name: \" + str(data.shape[0]))\n",
    "\n",
    "# Select only specific RX Devices by SerialNumber, just to make sure our images are similar\n",
    "if filterByDeviceSerialNumber:\n",
    "    data = data[data.DeviceSerialNumber.isin(DeviceSerialNumber)]\n",
    "    print(\"Number of images after filtering by DeviceSN: \" + str(data.shape[0]))\n",
    "\n",
    "# Assign whether they're Cases or Controls \n",
    "data[\"Case_type\"] = np.where((data.Dies_desde_positiu<=max_days_control_since_positive) | (data.Dies_desde_positiu.isna()),\"Control\",\"Case\")\n",
    "    # We could've used np.select when we have more than 2 conditions: https://stackoverflow.com/questions/19913659/pandas-conditional-creation-of-a-series-dataframe-column\n",
    "\n",
    "# NULL removal of predicted variable\n",
    "data = data[data[columnToPredict].isna()==False]\n",
    "print(\"Number of images after removing cases where predicted variable is NULL: \" + str(data.shape[0]))\n",
    "\n",
    "# Prevent patients to be in different cases. COVID preference.\n",
    "if patientOnlyInOneCase:\n",
    "    data = data[~(data.PatientId.isin(data.PatientId[data.Case_type == \"Case\"])) | (data.Case_type == \"Case\")]\n",
    "    print(\"Number of images after limiting patients to be in just one case_type: \" + str(data.shape[0]))\n",
    "\n",
    "# Keep just one image per Patient and ViewPosition\n",
    "if keepOneImage_PatientViewPosition:\n",
    "    data = data.drop_duplicates(subset=[\"PatientId\", \"ViewPosition\"])\n",
    "    print(\"Number of images after keeping just one image per Patient and ViewPosition: \" + str(data.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data cleaning / manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Control    31048\n",
       "Case        7015\n",
       "Name: Case_type, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove unnecessary columns\n",
    "data = data.drop(columns=[\"AFECTAT\", \"AFECTAT_PCR\", \"StudyDate\", \"BurnedInAnnotation\"])\n",
    "# data = data.rename(columns = {'destination_path':'path'})\n",
    "\n",
    "# Convert columnToPredict to string, just in case they're numbers, so we don't have any errors.\n",
    "data[columnToPredict] = data[columnToPredict].astype(str)\n",
    "\n",
    "# Classes to predict\n",
    "class_names = sorted(data[columnToPredict].unique())\n",
    "num_class = len(class_names)\n",
    "data[columnToPredict].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 38063 | RX with patients in more than one RX: 15157 | RX with patients in just that RX: 22906\n"
     ]
    }
   ],
   "source": [
    "# We'll leave patients with just one RX at the bottom of the dataset. This data will be validation and test and for sure will be patients that were not in the training set\n",
    "# We also shuffle Dataset so we can later split it into Train/Validation/Test without shuffling. This is important, since this way we'll be able to retrain without mixing datasets.\n",
    "\n",
    "data_multiple_rx = data[data.duplicated(subset=[\"PatientId\"], keep=False)]\n",
    "data_multiple_rx = data_multiple_rx.sample(frac=1, random_state=random_seed)\n",
    "data_unique_rx = data[~data.duplicated(subset=[\"PatientId\"], keep=False)]\n",
    "data_unique_rx = data_unique_rx.sample(frac=1, random_state=random_seed)\n",
    "\n",
    "data = data_multiple_rx.append(data_unique_rx, ignore_index=True)\n",
    "\n",
    "print(f'Total: {data.shape[0]} | RX with patients in more than one RX: {data_multiple_rx.shape[0]} | RX with patients in just that RX: {data_unique_rx.shape[0]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cohort save\n",
    "data.to_csv(path_or_buf=os.path.join(working_directory,'cohort_covid_20201110.csv'), index=False, sep='|')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "MedNIST_tutorial.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "MONAI Pytorch - Marc 2",
   "language": "python",
   "name": "marc-monai-2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
